---
title: 'Collaborative code generation with LLMs'
published: March 27, 2023
author: chris-ostrouchov
description: >
    Description TODO
category: ["ML", "LLM", "python"]
featuredImage:
  src: ...
  alt: ...
hero:
  imageSrc: ...
  imageAlt: ...
---

<base target="_blank" />

Large Language Models (LLMs) have revolutionized the field of natural
language processing (NLP) and artificial intelligence (AI), opening up
a world of possibilities across various domains. These models have
been trained on vast amounts of data and are capable of generating
human-like responses to a wide range of queries. The developer
community has seen especially good results due to the large amount of
source code available online for training.

Github's Co-pilot is a tool which will autocomplete code for a
developer but lacks the ability to interact with the completation,
provide feedback, and enforce a test suite on the generated code.

As an experiment we developed a python package
[pseudocode](https://github.com/Quansight/pseudocode) which much like
its name implies allows developers to annotate their code with
pseudocode and produce testable code generated by LLMs without the
user writing any code. We hope that
[pseudocode](https://github.com/Quansight/pseudocode) may be a "higher
level language" for writing python code. Below you will find an
example. We emphasize interfaces via type annotations and function
docstrings and provide easy ways to have automated tests.

```python
from pseudocode import pseudo_function

@pseudo_function(review=True)
def my_sum_func(a: int, b: int, c: int) -> str:
    """A fun sum function

    The function does the following:
     - adds all arguments together
     - then multiplies by two

    Examples
    --------
    >>> my_sum_func(1, 2, 3)
    12
    """
    pass

my_sum_func(1, 3, 4)
```

One of the key features of this library is its powerful feedback loop,
which benefits both the developer and the Large Language Model
(LLM). This feedback loop enables the library to generate high-quality
code that is fine-tuned to the developer's preferences. Additionally
the LLM backends are pluggable. While this demonstration does depend
on OpenAI it would be easy enough to add support for additional
backends.

With every code block generated by the LLM, the library prompts the
user to provide optional feedback on how they would like to fine-tune
their code. This allows developers to have greater control over the
code generation process and ensures that the generated code meets
their specific needs and requirements.

Once the user is satisfied with the generated code, the library
automatically runs all defined tests with Examples to validate the
code's functionality. This enables automated testing of the generated
code and helps ensure that it meets the desired specifications.

[![asciicast](https://asciinema.org/a/571026.svg)](https://asciinema.org/a/571026)

Check out the project at [Quansight/pseudocode](https://github.com/quansight/pseudocode).
